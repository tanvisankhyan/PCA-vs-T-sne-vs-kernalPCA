# -*- coding: utf-8 -*-
"""PCA_vs_tsne_vs_KernalPCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ay4ATMLYJ6uSqJn_t9BdBs-LdX69HzYl

```
# Tanvi Sankhyan
```
```
# Studend ID - 1188007
```
```
# Assignment 2- Dimension Reduction Technique
```
```
# PCA vs t-sne vs KernalPCA **bold text**
```

Dimension Reduction Technique - Sometimes the dataset we use has to many co-realted variable that it gets computationally expensive hence Dimension resuction is a techniques or bunch of tecchniques that reduces the dimensionality of our data while still retaining its information.

PCA - compresses the dimensions. It is based on eigen vectrs of the variance of the dataset. PCA finds a new set of dimensions such that all the dimensions are orthogonal and thus linearly independent.
"""

import pandas as pd
import numpy as np
from keras.datasets import mnist

(X_train, y_train), (X_test, y_test) = mnist.load_data()
print(f'X_train: {X_train.shape}')
print(f'X_test: {X_test.shape}')
print(f'y_train: {y_train.shape}')
print(f'y_test: {y_test.shape}')

X_train = X_train[:20000]
y_train = y_train[:20000]
X_train = X_train.reshape(-1, 28 * 28)
X_train.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
from sklearn.decomposition import PCA
pca = PCA(n_components=3)
Xtrain_pca = pca.fit_transform(X_train_std)
Xtrain_pca.shape

import plotly.graph_objects as go
result = pd.DataFrame(data={'Explained Variance Ratio': pca.explained_variance_ratio_})
result['cumulative'] = result['Explained Variance Ratio'].cumsum()
result['component'] = result.index + 1
fig = go.Figure(data=[go.Bar(x=result['component'], y=result['Explained Variance Ratio'], name='Explained Variance Ratio'),
                      go.Scatter(x=result['component'], y=result['cumulative'], name='cumulative')],
                layout=go.Layout(title='PCA - 3 components', width=950, template='plotly_dark'))
fig.show()

Xtrain_pca_df = pd.DataFrame(data=np.c_[Xtrain_pca, y_train], columns=['PCA 1', 'PCA 2', 'PCA 3', 'class'])
Xtrain_pca_df['class'] = Xtrain_pca_df['class'].astype(str)
Xtrain_pca_df.head()

import plotly.express as px
px.scatter(Xtrain_pca_df, x='PCA 1', y='PCA 2', color='class', opacity=0.9, width=900, title='PCA - 2 components', template='plotly_dark')

import plotly.express as px
px.scatter_3d(Xtrain_pca_df, x='PCA 1', y='PCA 2', z='PCA 3', color='class',symbol='class', opacity=0.7, size_max=10, width=950, height=550, 
              template='plotly_dark', title='PCA  3 Component')

"""T-sne"""

from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, verbose=1)
Xtrain_tsne = tsne.fit_transform(X_train_std)

Xtrain_tsne_df = pd.DataFrame(data=np.c_[Xtrain_tsne, y_train], columns=['TSNE 1', 'TSNE 2', 'class'])
Xtrain_tsne_df['class'] = Xtrain_tsne_df['class'].astype(str)
Xtrain_tsne_df

px.scatter(Xtrain_tsne_df, x='TSNE 1', y='TSNE 2', color='class', opacity=0.9, width=950, height=700,
           template='plotly_dark', title='TSNE - 2 components')

from plotly.subplots import make_subplots

fig = make_subplots(rows=1, cols=2, subplot_titles=['PCA', 't-SNE'], horizontal_spacing=0.03)

fig1 = px.scatter(Xtrain_pca_df, x='PCA 1', y='PCA 2', color='class', opacity=0.9)
fig2 = px.scatter(Xtrain_tsne_df, x='TSNE 1', y='TSNE 2', color='class', opacity=0.9)

for i in range(0, 10):
    fig.add_trace(fig1['data'][i], row=1, col=1)
    fig.add_trace(fig2['data'][i], row=1, col=2)
fig.update_layout(width=950, showlegend=False, template='plotly_dark')
fig.show()

tsne = TSNE(n_components=3, verbose=1)
Xtrain_tsne = tsne.fit_transform(Xtrain_pca)

Xtrain_tsne_df = pd.DataFrame(data=np.c_[Xtrain_tsne, y_train], columns=['TSNE 1', 'TSNE 2', 'TSNE 3', 'class'])
Xtrain_tsne_df['class'] = Xtrain_tsne_df['class'].astype(str)
Xtrain_tsne_df

px.scatter_3d(Xtrain_tsne_df, x='TSNE 1', y='TSNE 2', z='TSNE 3', color='class', symbol='class', opacity=0.7, size_max=10, width=950, height=550,
                template='plotly_dark', title='TSNE - 3 components')

"""KernalPCA"""

from sklearn.decomposition import KernelPCA
Kernel_pca = KernelPCA(n_components = 3, kernel= "rbf")
Xtrain_kernalPCA = Kernel_pca.fit_transform(X_train_std)

Xtrain_kernal_df = pd.DataFrame(data=np.c_[Xtrain_kernalPCA, y_train], columns=['KernalPCA 1', 'KernalPCA 2', 'KernalPCA 3', 'class'])
Xtrain_kernal_df['class'] = Xtrain_kernal_df['class'].astype(str)
Xtrain_kernal_df

px.scatter_3d(Xtrain_kernal_df, x='KernalPCA 1', y='KernalPCA 2', z='KernalPCA 3', color='class', opacity=0.5, width=950, height=700,
           template='plotly_dark', title='KernalPCA - 3 components')

px.scatter_3d(Xtrain_kernal_df, x='KernalPCA 1', y='KernalPCA 2', z='KernalPCA 3', color='class', symbol='class', opacity=0.7, size_max=10, width=950, height=550,
                template='plotly_dark', title='KernalPCA - 3 components')

Kernel_pca1 = KernelPCA(n_components = 2, kernel= "rbf")
Xtrain_kernalPCA1 = Kernel_pca1.fit_transform(X_train_std)